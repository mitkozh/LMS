input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/postgresql-42.2.5.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://postgres:5432/acs_library"
    jdbc_user => "postgres"
    jdbc_password => "toor"
    sql_log_level => "debug"
    clean_run => true
    record_last_run => true
    statement_filepath => "/usr/share/logstash/config/queries/from-scratch.sql"
    use_column_value => true
    tracking_column => "updated_at"
    tracking_column_type => "timestamp"
    last_run_metadata_path => "/usr/share/logstash/last_run_metadata"
    schedule => "* * * * *"
  }
}

filter {
  mutate {
    remove_field => ["@version", "@timestamp"]
  }
  if [deleted] {
    mutate {
      add_field => { "[@metadata][action]" => "delete" }
    }
  } else {
    mutate {
      add_field => { "[@metadata][action]" => "index" }
    }
  }
   mutate {
     strip => ["categories", "authors"]
   }
ruby {
  code => "
    categories = event.get('categories').split(', ')
    hierarchicalCategories = Hash.new { |h, k| h[k] = [] }
    uniqueCategories = []
    categories.each do |category|
      hierarchy = category.split('->').map(&:strip)
      hierarchy.each_with_index do |level, level_index|
        hierarchicalCategories['lvl' + level_index.to_s] << hierarchy[0..level_index].join(' > ')
      end
      uniqueCategories += hierarchy
    end
    event.set('hierarchicalCategories', hierarchicalCategories)
    event.set('categories', uniqueCategories.uniq)
    authors = event.get('authors').split(',')
    authors.map! do |author|
      id, name = author.split(':')
      { 'name' => name.strip, 'id' => id.strip }
    end
    event.set('authors', authors)
  "
}
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "books"
    document_id => "%{id}"
    action => "%{[@metadata][action]}"
  }
}
